#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
train_stage3.py
Stage-3 RL fine-tuning (REINFORCE/SCST) following the paper.
Uses fake forward model as surrogate (can be replaced by real simulator).
"""

import os
import numpy as np
import torch
import torch.nn.functional as F
from torch.optim import AdamW

from config_stage3 import TrainConfig
from models.metagpt import MetaGPT
from models.transformer_sdpa import TransformerConfig
from models.spectrum_encoder import SpectrumEncoder
from structure_lang.tokenizer import StructureTokenizer
from structure_lang.parser import StructureParser
from structure_lang.validator import StructureValidator
from data.gen_stage2_fake_dataset import fake_spectrum_from_structure
from utils import save_checkpoint, load_checkpoint, SimpleLogger, set_seed


def classify_token(token: str):
    if token.startswith("PX_"):
        return "PX"
    if token.startswith("PY_"):
        return "PY"
    if token.startswith("SUB_"):
        return "SUB"
    if token.startswith("L1_MAT_"):
        return "MAT"
    if token.startswith("L1_SHAPE_"):
        return "SHAPE"
    if token.startswith("L1_H_"):
        return "H"
    if token.startswith("L1_R_"):
        return "R"
    if token.startswith("L1_W_"):
        return "W"
    if token.startswith("L1_L_"):
        return "L"
    return "OTHER"


def extract_num(token: str):
    return int(token.split("_")[-1])


def apply_constraints(logits, token_strings, generated_tokens, px=None, py=None, shape=None, margin=30):
    vocab = len(token_strings)
    mask = torch.zeros(vocab, dtype=torch.bool, device=logits.device)

    if px is None:
        need = "PX"
    elif py is None:
        need = "PY"
    elif shape is None:
        if not any(tok.startswith("SUB_") for tok in generated_tokens):
            need = "SUB"
        elif not any(tok.startswith("L1_MAT_") for tok in generated_tokens):
            need = "MAT"
        else:
            need = "SHAPE"
    else:
        if shape == "CYL":
            if not any(tok.startswith("L1_H_") for tok in generated_tokens):
                need = "H"
            elif not any(tok.startswith("L1_R_") for tok in generated_tokens):
                need = "R"
            else:
                need = "EOS"
        else:
            if not any(tok.startswith("L1_H_") for tok in generated_tokens):
                need = "H"
            elif not any(tok.startswith("L1_W_") for tok in generated_tokens):
                need = "W"
            elif not any(tok.startswith("L1_L_") for tok in generated_tokens):
                need = "L"
            else:
                need = "EOS"

    for tid, token in enumerate(token_strings):
        cls = classify_token(token)
        if need == "EOS" and token == "[EOS]":
            mask[tid] = True
        elif need == cls:
            mask[tid] = True

    for tid, tok in enumerate(token_strings):
        if tok in ("[PAD]", "[BOS]"):
            mask[tid] = False

    if px is not None and py is not None:
        Pmin = min(px, py)
        if need == "R":
            limit = Pmin / 2 - margin
            for tid, token in enumerate(token_strings):
                if token.startswith("L1_R_"):
                    val = extract_num(token)
                    mask[tid] = val <= limit
        if need in ("W", "L"):
            limit = Pmin - margin
            for tid, token in enumerate(token_strings):
                if token.startswith(f"L1_{need}_"):
                    val = extract_num(token)
                    mask[tid] = val <= limit

    if mask.sum() == 0:
        return logits

    logits = logits.clone()
    logits[~mask] = -1e10
    return logits


def tokens_to_struct(tokens):
    keep = []
    for t in tokens:
        if t.startswith("PX_") or t.startswith("PY_") or t.startswith("SUB_") or t.startswith("L1_"):
            keep.append(t)
    return keep


def _cfg_from_ckpt(ckpt):
    if "model_cfg" in ckpt:
        cfg = ckpt["model_cfg"]
        if isinstance(cfg, dict):
            return TransformerConfig(**cfg)
        return cfg
    raise KeyError("Checkpoint missing model_cfg")


def _align_state_dict(state, model):
    model_state = model.state_dict()
    for key in ("tok_embed.lut.weight", "lm_head.weight"):
        if key in state and key in model_state:
            if state[key].shape != model_state[key].shape:
                new_w = model_state[key].clone()
                n = min(state[key].shape[0], new_w.shape[0])
                new_w[:n] = state[key][:n]
                state[key] = new_w
    return state


def spectrum_from_struct_det(struct_toks, spec_dim: int):
    seed = abs(hash(" ".join(struct_toks))) % (2**32)
    rng = np.random.default_rng(seed)
    return fake_spectrum_from_structure(struct_toks, spec_dim=spec_dim, rng=rng)


@torch.no_grad()
def generate_rollout(model, spectra, tk, cfg: TrainConfig, greedy: bool):
    device = spectra.device
    B = spectra.size(0)
    out = torch.full((B, 1), tk.bos_id, device=device, dtype=torch.long)
    finished = torch.zeros(B, dtype=torch.bool, device=device)

    token_strings = tk.id_to_token
    generated_tokens = [[] for _ in range(B)]
    px = [None] * B
    py = [None] * B
    shape = [None] * B

    for _ in range(cfg.max_new):
        logits, _, _ = model(input_ids=out, spectra=spectra)
        next_logits = logits[:, -1, :]

        if cfg.use_grammar:
            for b in range(B):
                if finished[b]:
                    continue
                next_logits[b] = apply_constraints(
                    next_logits[b],
                    token_strings=token_strings,
                    generated_tokens=generated_tokens[b],
                    px=px[b],
                    py=py[b],
                    shape=shape[b],
                    margin=cfg.grammar_margin,
                )

        if greedy:
            next_id = torch.argmax(next_logits, dim=-1)
        else:
            p = next_logits / max(cfg.temperature, 1e-8)
            if cfg.top_k > 0:
                v, _ = torch.topk(p, k=min(cfg.top_k, p.size(-1)))
                kth = v[:, -1].unsqueeze(-1)
                p = torch.where(p < kth, torch.full_like(p, -1e9), p)
            if cfg.top_p < 1.0:
                sorted_p, sorted_idx = torch.sort(p, descending=True)
                probs = torch.softmax(sorted_p, dim=-1)
                cdf = probs.cumsum(dim=-1)
                cutoff = cdf > cfg.top_p
                cutoff[:, 0] = False
                sorted_p = torch.where(cutoff, torch.full_like(sorted_p, -1e9), sorted_p)
                p = torch.zeros_like(p).scatter(-1, sorted_idx, sorted_p)
            probs = torch.softmax(p, dim=-1)
            next_id = torch.multinomial(probs, 1).squeeze(-1)

        next_id = torch.where(finished, torch.full_like(next_id, tk.eos_id), next_id)
        out = torch.cat([out, next_id.unsqueeze(1)], dim=1)

        for b in range(B):
            if finished[b]:
                continue
            tok = token_strings[next_id[b].item()]
            if tok == "[EOS]":
                finished[b] = True
                continue
            generated_tokens[b].append(tok)
            if tok.startswith("PX_"):
                px[b] = extract_num(tok)
            elif tok.startswith("PY_"):
                py[b] = extract_num(tok)
            elif tok.startswith("L1_SHAPE_"):
                shape[b] = tok.split("_")[-1]

        if finished.all():
            break

    return out


@torch.no_grad()
def compute_reward(tokens, spectra, tk, parser, validator, invalid_penalty: float):
    B = spectra.size(0)
    rewards = []
    for b in range(B):
        ids = tokens[b].tolist()
        if tk.eos_id in ids:
            ids = ids[: ids.index(tk.eos_id) + 1]
        toks = tk.decode([i for i in ids if i in tk.inv_vocab])
        struct_toks = tokens_to_struct(toks)

        ok, _ = validator.validate(parser.parse(["[BOS]"] + struct_toks + ["[EOS]"]))
        if not ok:
            r = torch.tensor(invalid_penalty, device=spectra.device)
        else:
            pred = spectrum_from_struct_det(struct_toks, spec_dim=spectra.size(1))
            pred_spec = torch.tensor(pred, device=spectra.device)
            r = -torch.mean((pred_spec - spectra[b]) ** 2)
        rewards.append(r)
    return torch.stack(rewards, dim=0)


def sequence_logprob(model, spectra, tokens, eos_id: int):
    inp = tokens[:, :-1].contiguous()
    lab = tokens[:, 1:].contiguous()
    logits, _, _ = model(input_ids=inp, spectra=spectra, labels=None)
    logp = F.log_softmax(logits, dim=-1)
    token_logp = logp.gather(-1, lab.unsqueeze(-1)).squeeze(-1)

    # mask after EOS
    B, T = lab.shape
    mask = torch.ones((B, T), device=lab.device, dtype=torch.float32)
    for b in range(B):
        eos_pos = (lab[b] == eos_id).nonzero(as_tuple=False)
        if eos_pos.numel() > 0:
            first = int(eos_pos[0].item())
            if first + 1 < T:
                mask[b, first + 1 :] = 0.0
    seq_logp = (token_logp * mask).sum(dim=-1)
    return seq_logp, logits


def train_stage3():
    cfg = TrainConfig()
    set_seed(cfg.seed)
    log = SimpleLogger()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    os.makedirs(cfg.save_dir, exist_ok=True)

    # load spectra
    spec_arr = np.load(cfg.spec_file).astype("float32")
    log.log(f"Loaded spectra: {spec_arr.shape}")

    # tokenizer / parser / validator
    tk = StructureTokenizer()
    tk.id_to_token = [tk.inv_vocab[i] for i in range(tk.vocab_size)]
    parser = StructureParser()
    validator = StructureValidator(min_feature_nm=20, margin_nm=30)

    # load SFT checkpoint
    ckpt = torch.load(cfg.stage2_ckpt, map_location="cpu")
    model_cfg = _cfg_from_ckpt(ckpt)
    meta = ckpt.get("meta", {})
    spec_dim = int(meta.get("spec_dim", spec_arr.shape[1]))
    prefix_len = int(meta.get("prefix_len", 16))
    pad_id = int(meta.get("pad_id", tk.pad_id))
    bos_id = int(meta.get("bos_id", tk.bos_id))
    eos_id = int(meta.get("eos_id", tk.eos_id))

    model = MetaGPT(cfg=model_cfg, spec_dim=spec_dim, prefix_len=prefix_len, pad_id=pad_id).to(device)
    model.encoder = SpectrumEncoder(spec_dim=spec_dim, d_model=model_cfg.d_model, prefix_len=prefix_len).to(device)

    state = _align_state_dict(ckpt["model"], model)
    model.load_state_dict(state, strict=False)
    log.log(f"Loaded SFT weights: {cfg.stage2_ckpt}")

    optim = AdamW(model.parameters(), lr=cfg.lr)

    start_step = 0
    if cfg.resume:
        start_step, _ = load_checkpoint(cfg.resume, model, optim, scaler=None, strict=True)
        log.log(f"Resumed from {cfg.resume} at step={start_step}")

    model.train()

    base_meta = {
        "spec_dim": spec_dim,
        "prefix_len": prefix_len,
        "pad_id": pad_id,
        "bos_id": bos_id,
        "eos_id": eos_id,
        "d_model": model_cfg.d_model,
        "vocab_size": model_cfg.vocab_size,
    }

    for step in range(start_step, cfg.steps):
        idx = np.random.randint(0, spec_arr.shape[0], size=cfg.batch_size)
        spectra = torch.tensor(spec_arr[idx], device=device)

        # sample rollout
        sample_tokens = generate_rollout(model, spectra, tk, cfg, greedy=False)
        r_sample = compute_reward(sample_tokens, spectra, tk, parser, validator, cfg.invalid_penalty)

        # greedy baseline
        base_tokens = generate_rollout(model, spectra, tk, cfg, greedy=True)
        r_base = compute_reward(base_tokens, spectra, tk, parser, validator, cfg.invalid_penalty)

        adv = (r_sample - r_base).detach()

        seq_logp, logits = sequence_logprob(model, spectra, sample_tokens, eos_id=eos_id)
        loss_pg = -(adv * seq_logp).mean()

        if cfg.entropy_beta > 0:
            probs = torch.softmax(logits, dim=-1)
            entropy = -(probs * torch.log(probs.clamp(min=1e-12))).sum(dim=-1).mean()
            loss = loss_pg - cfg.entropy_beta * entropy
        else:
            loss = loss_pg

        optim.zero_grad(set_to_none=True)
        loss.backward()
        if cfg.grad_clip > 0:
            torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)
        optim.step()

        if (step + 1) % cfg.log_every == 0:
            log.log(
                f"step={step+1} loss={loss.item():.4f} r_sample={r_sample.mean().item():.4f} "
                f"r_base={r_base.mean().item():.4f} adv={adv.mean().item():.4f}"
            )

        if (step + 1) % cfg.save_every == 0:
            ck = os.path.join(cfg.save_dir, f"rl_step{step+1}.pt")
            payload = {
                "model": model.state_dict(),
                "model_cfg": model_cfg,
                "meta": base_meta,
                "step": step + 1,
                "extra": {},
            }
            torch.save(payload, ck)
            log.log(f"saved {ck}")


if __name__ == "__main__":
    train_stage3()
