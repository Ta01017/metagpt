# structure_lang/tokenizer.py
import json


class StructureTokenizer:
    """
    å°† metasurface å•å…ƒç»“æ„åºåˆ—æ˜ å°„åˆ° token idï¼ˆæ•´æ•°ï¼‰
    æ”¯æŒï¼š
      - encode: tokens â†’ ids
      - decode: ids â†’ tokens
      - ä¿å­˜ä¸åŠ è½½è¯è¡¨
    """

    def __init__(self):
        self.materials = [
            'MgF2','SiO2','ZnO','MgO','Si3N4','HfO2',
            'TiO2','Ta2O5','AlN','Nb2O5','ZnS','ZnSe'
        ]

        # å‚æ•°ç©ºé—´ï¼ˆå¯è°ƒï¼‰
        self.P_vals = list(range(300, 1001, 10))    # PX/PY
        self.H_vals = list(range(50, 1201, 10))     # height
        self.R_vals = list(range(20, 501, 10))      # radius
        self.W_vals = list(range(20, 801, 10))      # width/length

        self.special_tokens = ["[PAD]","[BOS]","[EOS]"]

        self.vocab = {}
        self.inv_vocab = {}
        self._build_vocab()

        # expose common ids/sizes
        self.pad_id = self.vocab["[PAD]"]
        self.bos_id = self.vocab["[BOS]"]
        self.eos_id = self.vocab["[EOS]"]
        self.vocab_size = len(self.vocab)

    # --------------------------------------------------------
    # Build vocab
    # --------------------------------------------------------
    def _build_vocab(self):
        idx = 0
        for t in self.special_tokens:
            self.vocab[t] = idx; idx += 1

        # PX, PY
        for P in self.P_vals:
            self.vocab[f"PX_{P}"] = idx; idx += 1
            self.vocab[f"PY_{P}"] = idx; idx += 1

        # substrate
        self.vocab["SUB_Glass_Substrate"] = idx; idx += 1

        # materials
        for m in self.materials:
            self.vocab[f"L1_MAT_{m}"] = idx; idx += 1

        # shapes
        shapes = ["CYL", "RECT"]
        for sh in shapes:
            self.vocab[f"L1_SHAPE_{sh}"] = idx; idx += 1

        # height
        for H in self.H_vals:
            self.vocab[f"L1_H_{H}"] = idx; idx += 1

        # CYL radius
        for R in self.R_vals:
            self.vocab[f"L1_R_{R}"] = idx; idx += 1

        # RECT width/length
        for W in self.W_vals:
            self.vocab[f"L1_W_{W}"] = idx; idx += 1
            self.vocab[f"L1_L_{W}"] = idx; idx += 1

        # CoT tokens (append to preserve existing ids)
        self.cot_tokens = ["[COT]"]
        self.cot_tokens += [f"COT_MAT_{m}" for m in self.materials]
        self.cot_tokens += ["COT_SHAPE_CYL", "COT_SHAPE_RECT"]
        for t in self.cot_tokens:
            if t not in self.vocab:
                self.vocab[t] = idx; idx += 1

        self.inv_vocab = {v:k for k,v in self.vocab.items()}

    # --------------------------------------------------------
    # Encode / Decode
    # --------------------------------------------------------
    def encode(self, tokens):
        return [self.vocab[t] for t in tokens]

    def decode(self, ids):
        return [self.inv_vocab[i] for i in ids]

    # --------------------------------------------------------
    # Save / Load
    # --------------------------------------------------------
    def save_vocab(self, path):
        with open(path, "w", encoding="utf-8") as f:
            json.dump(self.vocab, f, indent=2)

    @staticmethod
    def load_vocab(path):
        with open(path, "r", encoding="utf-8") as f:
            vocab = json.load(f)

        tk = StructureTokenizer()
        tk.vocab = vocab
        tk.inv_vocab = {v:k for k,v in vocab.items()}
        return tk

class StructureTokenizerExtended(StructureTokenizer):
    """æ‰©å±•çš„StructureTokenizerï¼Œæ”¯æŒå®é™…æ•°æ®å‚æ•°èŒƒå›´"""
    
    def __init__(self):
        super().__init__()
        
        # æ‰©å±•å‚æ•°èŒƒå›´ä»¥é€‚é…å®é™…æ•°æ®
        self._extend_parameter_ranges()
        self._rebuild_vocab_with_extended_ranges()
    
    def _extend_parameter_ranges(self):
        """æ‰©å±•å‚æ•°èŒƒå›´"""
        # åŸºäºå¤±è´¥æ ·æœ¬åˆ†æï¼Œæ‰©å±•å‚æ•°èŒƒå›´
        print("ğŸ”§ æ‰©å±•å‚æ•°èŒƒå›´ä»¥é€‚é…å®é™…æ•°æ®...")
        
        # æ‰©å±•PèŒƒå›´ï¼šæ”¯æŒæ›´å°çš„å‘¨æœŸ
        original_P_min = min(self.P_vals)
        if original_P_min > 50:  # å¦‚æœæœ€å°På¤§äº50nmï¼Œæ·»åŠ æ›´å°çš„å€¼
            self.P_vals = [50] + self.P_vals
            print(f"  PèŒƒå›´æ‰©å±•: æ·»åŠ 50nm")
        
        # æ‰©å±•RèŒƒå›´ï¼šæ”¯æŒæ›´å°çš„åŠå¾„
        original_R_min = min(self.R_vals) 
        if original_R_min > 30:  # æ”¯æŒå°åˆ°30nmçš„åŠå¾„
            new_R_vals = [30, 40] + self.R_vals
            self.R_vals = sorted(list(set(new_R_vals)))  # å»é‡å¹¶æ’åº
            print(f"  RèŒƒå›´æ‰©å±•: æ·»åŠ 30nm, 40nm")
        
        # æ‰©å±•HèŒƒå›´ï¼šæ”¯æŒæ›´å¤§çš„é«˜åº¦
        original_H_max = max(self.H_vals)
        if original_H_max < 800:  # å¦‚æœæœ€å¤§Hå°äº800nmï¼Œæ·»åŠ æ›´å¤§çš„å€¼
            additional_H = [h for h in range(original_H_max + 50, 1001, 50)]
            self.H_vals.extend(additional_H)
            self.H_vals = sorted(list(set(self.H_vals)))
            print(f"  HèŒƒå›´æ‰©å±•: æœ€å¤§åˆ°{max(self.H_vals)}nm")
        
        print(f"  æœ€ç»ˆå‚æ•°èŒƒå›´:")
        print(f"    P_vals: {self.P_vals}")
        print(f"    R_vals: {self.R_vals}") 
        print(f"    H_vals: {self.H_vals}")
    
    def _rebuild_vocab_with_extended_ranges(self):
        """ä½¿ç”¨æ‰©å±•çš„å‚æ•°èŒƒå›´é‡æ–°æ„å»ºè¯è¡¨"""
        # ä¿å­˜ç‰¹æ®Štokençš„ID
        special_ids = {token: self.vocab[token] for token in self.special_tokens}
        
        # é‡æ–°æ„å»ºè¯è¡¨
        self.vocab = {}
        self.inv_vocab = {}
        idx = 0
        

        # ç‰¹æ®Štoken
        for t in self.special_tokens:
            self.vocab[t] = idx; idx += 1

        # PX, PY (ä½¿ç”¨æ‰©å±•åçš„P_vals)
        for P in self.P_vals:
            self.vocab[f"PX_{P}"] = idx; idx += 1
            self.vocab[f"PY_{P}"] = idx; idx += 1

        # substrate
        self.vocab["SUB_Glass_Substrate"] = idx; idx += 1

        # materials (åŒ…å«Si-Alpha)
        self.materials = ["SiO2", "TiO2", "Si-Alpha"]  # ç¡®ä¿åŒ…å«Si-Alpha
        for m in self.materials:
            self.vocab[f"L1_MAT_{m}"] = idx; idx += 1

        # shapes
        shapes = ["CYL", "RECT"]
        for sh in shapes:
            self.vocab[f"L1_SHAPE_{sh}"] = idx; idx += 1

        # height (ä½¿ç”¨æ‰©å±•åçš„H_vals)
        for H in self.H_vals:
            self.vocab[f"L1_H_{H}"] = idx; idx += 1

        # CYL radius (ä½¿ç”¨æ‰©å±•åçš„R_vals)
        for R in self.R_vals:
            self.vocab[f"L1_R_{R}"] = idx; idx += 1

        # RECT width/length
        for W in self.W_vals:
            self.vocab[f"L1_W_{W}"] = idx; idx += 1
            self.vocab[f"L1_L_{W}"] = idx; idx += 1

        # CoT tokens
        self.cot_tokens = ["[COT]"]
        self.cot_tokens += [f"COT_MAT_{m}" for m in self.materials]
        self.cot_tokens += ["COT_SHAPE_CYL", "COT_SHAPE_RECT"]
        for t in self.cot_tokens:
            if t not in self.vocab:
                self.vocab[t] = idx; idx += 1

        self.inv_vocab = {v:k for k,v in self.vocab.items()}
        
        # é‡æ–°è®¾ç½®å¸¸ç”¨ID
        self.pad_id = self.vocab["[PAD]"]
        self.bos_id = self.vocab["[BOS]"]
        self.eos_id = self.vocab["[EOS]"]
        self.vocab_size = len(self.vocab)
        
        print(f"  è¯è¡¨å¤§å°: {self.vocab_size}")


        # ç‰¹æ®Štoken
        for t in self.special_tokens:
            self.vocab[t] = idx; idx += 1

        # PX, PY (ä½¿ç”¨æ‰©å±•åçš„P_vals)
        for P in self.P_vals:
            self.vocab[f"PX_{P}"] = idx; idx += 1
            self.vocab[f"PY_{P}"] = idx; idx += 1

        # substrate
        self.vocab["SUB_Glass_Substrate"] = idx; idx += 1

        # materials (åŒ…å«Si-Alpha)
        self.materials = ["SiO2", "TiO2", "Si-Alpha"]  # ç¡®ä¿åŒ…å«Si-Alpha
        for m in self.materials:
            self.vocab[f"L1_MAT_{m}"] = idx; idx += 1

        # shapes
        shapes = ["CYL", "RECT"]
        for sh in shapes:
            self.vocab[f"L1_SHAPE_{sh}"] = idx; idx += 1

        # height (ä½¿ç”¨æ‰©å±•åçš„H_vals)
        for H in self.H_vals:
            self.vocab[f"L1_H_{H}"] = idx; idx += 1

        # CYL radius (ä½¿ç”¨æ‰©å±•åçš„R_vals)
        for R in self.R_vals:
            self.vocab[f"L1_R_{R}"] = idx; idx += 1

        # RECT width/length
        for W in self.W_vals:
            self.vocab[f"L1_W_{W}"] = idx; idx += 1
            self.vocab[f"L1_L_{W}"] = idx; idx += 1

        # CoT tokens
        self.cot_tokens = ["[COT]"]
        self.cot_tokens += [f"COT_MAT_{m}" for m in self.materials]
        self.cot_tokens += ["COT_SHAPE_CYL", "COT_SHAPE_RECT"]
        for t in self.cot_tokens:
            if t not in self.vocab:
                self.vocab[t] = idx; idx += 1

        self.inv_vocab = {v:k for k,v in self.vocab.items()}
        
        # é‡æ–°è®¾ç½®å¸¸ç”¨ID
        self.pad_id = self.vocab["[PAD]"]
        self.bos_id = self.vocab["[BOS]"]
        self.eos_id = self.vocab["[EOS]"]
        self.vocab_size = len(self.vocab)
        
        print(f"  è¯è¡¨å¤§å°: {self.vocab_size}")


    def analyze_parameter_distribution(self, folder_path: str):
        """åˆ†æå®é™…æ•°æ®ä¸­çš„å‚æ•°åˆ†å¸ƒ"""
        import glob
        import re
        from pathlib import Path
        
        mat_files = glob.glob(os.path.join(folder_path, "*.mat"))
        print(f"\nğŸ“Š åˆ†æ {len(mat_files)} ä¸ªæ–‡ä»¶çš„å‚æ•°åˆ†å¸ƒ...")
        
        all_P = []
        all_R = []  # åŠå¾„ = D/2
        all_H = []
        
        for file_path in mat_files[:1000]:  # æŠ½æ ·åˆ†æå‰1000ä¸ªæ–‡ä»¶
            try:
                filename = Path(file_path).name
                pattern = r'T_P([\d\.e+-]+)_D([\d\.e+-]+)_H([\d\.e+-]+)_num-idx(\d+)\.mat'
                match = re.match(pattern, filename)
                
                if match:
                    P, D, H, idx = match.groups()
                    P_nm = float(P) * 1e9
                    R_nm = (float(D) / 2) * 1e9  # ç›´å¾„è½¬åŠå¾„
                    H_nm = float(H) * 1e9
                    
                    all_P.append(P_nm)
                    all_R.append(R_nm)
                    all_H.append(H_nm)
            except:
                continue
        
        if all_P:
            print(f"  PèŒƒå›´: {min(all_P):.1f} - {max(all_P):.1f} nm")
            print(f"  RèŒƒå›´: {min(all_R):.1f} - {max(all_R):.1f} nm") 
            print(f"  HèŒƒå›´: {min(all_H):.1f} - {max(all_H):.1f} nm")
            
            # æ£€æŸ¥è¶…å‡ºèŒƒå›´çš„æ ·æœ¬
            p_out_of_range = [p for p in all_P if p < min(self.P_vals) or p > max(self.P_vals)]
            r_out_of_range = [r for r in all_R if r < min(self.R_vals) or r > max(self.R_vals)]
            h_out_of_range = [h for h in all_H if h < min(self.H_vals) or h > max(self.H_vals)]
            
            print(f"  è¶…å‡ºå½“å‰èŒƒå›´çš„æ ·æœ¬:")
            print(f"    P: {len(p_out_of_range)}/{len(all_P)}")
            print(f"    R: {len(r_out_of_range)}/{len(all_R)}")
            print(f"    H: {len(h_out_of_range)}/{len(all_H)}")